{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto 2 - Classificador Automático de Sentimento\n",
    "\n",
    "## Ana Beatriz Henriques e Anna Beathriz de Mauro       \n",
    "<h3>2C - 17/09/2017</h3>\n",
    "\n",
    "Você foi contratado por uma empresa parar analisar como os clientes estão reagindo a um determinado produto no Twitter. A empresa deseja que você crie um programa que irá analisar as mensagens disponíveis e classificará como \"relevante\" ou \"irrelevante\". Com isso ela deseja que mensagens negativas, que denigrem o nome do produto, ou que mereçam destaque, disparem um foco de atenção da área de marketing.<br /><br />\n",
    "Como aluno de Ciência dos Dados, você lembrou do Teorema de Bayes, mais especificamente do Classificador Naive-Bayes, que é largamente utilizado em filtros anti-spam de e-mails. O classificador permite calcular qual a probabilidade de uma mensagem ser relevante dadas as palavras em seu conteúdo.<br /><br />\n",
    "Para realizar o MVP (*minimum viable product*) do projeto, você precisa implementar uma versão do classificador que \"aprende\" o que é relevante com uma base de treinamento e compara a performance dos resultados com uma base de testes.<br /><br />\n",
    "Após validado, o seu protótipo poderá também capturar e classificar automaticamente as mensagens da plataforma.\n",
    "\n",
    "## Informações do Projeto\n",
    "\n",
    "Prazo: 13/Set até às 23:59.<br />\n",
    "Grupo: 2 pessoas.<br /><br />\n",
    "Entregáveis via GitHub: \n",
    "* Arquivo notebook com o código do classificador, seguindo as orientações abaixo.\n",
    "* Arquivo Excel com as bases de treinamento e teste totalmente classificado.\n",
    "\n",
    "**NÃO disponibilizar o arquivo com os *access keys/tokens* do Twitter.**\n",
    "\n",
    "\n",
    "### Check 3: \n",
    "\n",
    "Até o dia 06 de Setembro às 23:59, o notebook e o xlsx devem estar no Github com as seguintes evidências: \n",
    "    * Conta no twitter criada.\n",
    "    * Produto escolhido.\n",
    "    * Arquivo Excel contendo a base de treinamento e teste já classificado.\n",
    "    \n",
    "\n",
    "Sugestão de leitura:<br />\n",
    "http://docs.tweepy.org/en/v3.5.0/index.html<br />\n",
    "https://monkeylearn.com/blog/practical-explanation-naive-bayes-classifier/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "import math\n",
    "import os.path\n",
    "import pandas as pd\n",
    "import json\n",
    "from random import shuffle\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Classificando as Mensagens\n",
    "\n",
    "Agora você deve abrir o arquivo Excel com as mensagens capturadas e classificar na Coluna B se a mensagem é relevante ou não.<br /> \n",
    "Não se esqueça de colocar um nome para a coluna na célula **B1**.<br /><br />\n",
    "Fazer o mesmo na planilha de Controle.\n",
    "\n",
    "___\n",
    "## Montando o Classificador Naive-Bayes\n",
    "\n",
    "Com a base de treinamento montada, comece a desenvolver o classificador. Escreva o seu código abaixo:\n",
    "\n",
    "Opcionalmente: \n",
    "* Limpar as mensagens removendo os caracteres: enter, :, \", ', (, ), etc. Não remover emojis.<br />\n",
    "* Corrigir separação de espaços entre palavras e/ou emojis.\n",
    "* Propor outras limpezas/transformações que não afetem a qualidade da informação.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tudo = pd.ExcelFile('bobs1.xlsx')                #Arquivo\n",
    "dados = pd.read_excel(tudo, 'Treinamento')      #Planilha Treinamento\n",
    "teste = pd.read_excel(tudo, 'Teste')            #Planilha Teste"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Limpando as mensagens:</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(dados)):\n",
    "    caract=[',',';','.','!','?',\"(\",\")\", ':', '\"', \"'\"]      #caracteres que se desejam retirar\n",
    "    palavras = dados.Treinamento[i].split()                 # criando lista de listas de palavras em cada mensagem\n",
    "    letras=[]                                              #lista de lista de letras das palvras\n",
    "    final=[]                                                #lista de mensagens no final do processo\n",
    "    for x in palavras:                                      #passando palavra por palavra\n",
    "        letrasporpalavra=[]                                #lista que irá conter as letras das palavras no for\n",
    "        for a in range(len(x)):                            #passando letra por letra\n",
    "            letrasporpalavra.append(x[a])                   #adicionando cada letra na lista\n",
    "        letras.append(letrasporpalavra)                 #adicionando lista de lista com as letras\n",
    "    for z in letras:                                    #passando item/lista por lista\n",
    "        for w in z:                                     #dentro da lista, passando letra por letra\n",
    "            if w in caract:                            #se estiver entre os caracteres\n",
    "                d=z.index(w)                           #pega o indice desse caracter\n",
    "                z[d] = ' '                             #substitui ele na lista por um espaço\n",
    "    for q in range(len(letras)):                      #q vai passar pelos índices da lista letras (palavra por palavra)\n",
    "        junto = ''.join(letras[q])                    #junto vai tranformar a lista de letras em palavras           \n",
    "        if len(junto)!=0: \n",
    "            if junto[0] !='@' and junto[0:5]!='https' and junto!= 'rt' and junto[0:3]!='kkk':  #retira alguns outros itens\n",
    "                final.append(junto)                 #adiciona na lista final\n",
    "    for a in range(len(final)-1):                    #passando pelo índice de cada palavra\n",
    "        if final[a] =='de' and final[a+1] == 'bobs':  #juntando de bobs em uma palavra só\n",
    "            final[a]='debobs'\n",
    "            final[a+1]=''\n",
    "    dados.Treinamento[i] = ' '.join(final)         #junta as palavras das mensagens e substitui as mensagens de dados.Treinamento\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dados_relevante = dados[dados.relevancia=='r'].Treinamento\n",
    "dados_irrelevante = dados[dados.relevancia=='i'].Treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rel = []                           #cria lista que ira conter todas as palavras contidas nas mensagens relevantes\n",
    "for msg in dados_relevante:       #passa mensagem por mensagem\n",
    "    palavras = msg.split()         #separa as palvras\n",
    "    for x in palavras:             #adiciona as palavras na lista rel\n",
    "        rel.append(x)\n",
    "relevante = pd.DataFrame({\"Treinamento\":rel}).Treinamento.value_counts()/len(rel)*100   \n",
    "\n",
    "\n",
    "irrel = []                       #cria lista que ira conter todas as palavras contidas nas mensagens irrelevantes\n",
    "for msg in dados_irrelevante:    #passa mensagem por mensagem\n",
    "    palavras = msg.split()       #separa as palvras\n",
    "    for x in palavras:           #adiciona as palavras na lista rel\n",
    "        irrel.append(x)\n",
    "irrelevante = pd.DataFrame({\"Treinamento\":irrel}).Treinamento.value_counts()/len(irrel)*100\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Calculando porcentagens:</h3>\n",
    "<ul><li>Porcentagem de mensagens relevantes ou irrelevantes</li></ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantidademsgrelev=0               #cria variável que conterá o número de palavras consideradas relevantes\n",
    "quantidademsgirrelev=0              #cria variável que conterá o número de palavras consideradas irrelevantes\n",
    "for i in dados.relevancia:          #passa na coluna relevancia de mwnsagem por mensagem\n",
    "    if i=='r':                      #se for classificada como relevante adiciona 1 na quantidademsgrelev\n",
    "        quantidademsgrelev+=1\n",
    "    if i=='i':                      ##se for classificada como irrelevante adiciona 1 na quantidademsgirrelev\n",
    "        quantidademsgirrelev+=1\n",
    "        \n",
    "quantidademsgrelev=(quantidademsgrelev/len(dados.relevancia)) *100       #tranforma para porcentagem em relação ao total de msg\n",
    "quantidademsgirrelev=(quantidademsgirrelev/len(dados.relevancia))*100     #tranforma para porcentagem em relação ao total de msg\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul><li>Número de palavras relevantes ou irrelevantes</li></ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "rel = []                           #cria lista que ira conter todas as palavras contidas nas mensagens relevantes\n",
    "for msg in dados_relevante:       #passa mensagem por mensagem\n",
    "    palavras = msg.split()         #separa as palvras\n",
    "    for x in palavras:             #adiciona as palavras na lista rel\n",
    "        rel.append(x)\n",
    "\n",
    "\n",
    "irrel = []                       #cria lista que ira conter todas as palavras contidas nas mensagens irrelevantes\n",
    "for msg in dados_irrelevante:    #passa mensagem por mensagem\n",
    "    palavras = msg.split()       #separa as palvras\n",
    "    for x in palavras:           #adiciona as palavras na lista rel\n",
    "        irrel.append(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul><li>Calculando número de palavras diferentes</li></ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "palavrasdiferentes=[]                           #cria uma lista que irá conter as palavras diferentes\n",
    "for palavrarelevante in rel:                    #passa pelas palavras presentes na lista rel(palavras relevantes)\n",
    "    for palavrairrelevante in irrel:            #passa pelas palavras presentes na lista irrel(palavras irrelevantes)\n",
    "        if palavrarelevante!= palavrairrelevante:       # se as palavras forem diferentes\n",
    "            if palavrarelevante not in palavrasdiferentes:           # se a palavra não estiver em palavrasdiferentes, adiciona\n",
    "                palavrasdiferentes.append(palavrarelevante)\n",
    "            if palavrairrelevante not in palavrasdiferentes:\n",
    "                palavrasdiferentes.append(palavrairrelevante)            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul><li>Calculando probabilidade das palavras dado relevante ou irrelevante</li></ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cria dicionário com a porcentagem das palavras\n",
    "relevante = pd.DataFrame({\"Treinamento\":rel}).Treinamento.value_counts()/(len(rel)+len(palavrasdiferentes)) + (1/(len(rel)+len(palavrasdiferentes)))\n",
    "relevante=relevante*100\n",
    "irrelevante = pd.DataFrame({\"Treinamento\":irrel}).Treinamento.value_counts()/(len(irrel)+len(palavrasdiferentes)) + (1/(len(irrel)+len(palavrasdiferentes)))\n",
    "irrelevante=irrelevante*100\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Planilha Teste</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Limpando as mensagens:</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(teste)):\n",
    "    caract=[',',';','.','!','?',\"(\",\")\", ':', '\"', \"'\"]      #caracteres que se desejam retirar\n",
    "    palavras = teste.Teste[i].split()                 # criando lista de listas de palavras em cada mensagem\n",
    "    letras=[]                                              #lista de lista de letras das palvras\n",
    "    final=[]                                                #lista de mensagens no final do processo\n",
    "    for x in palavras:                                      #passando palavra por palavra\n",
    "        letrasporpalavra=[]                                #lista que irá conter as letras das palavras no for\n",
    "        for a in range(len(x)):                            #passando letra por letra\n",
    "            letrasporpalavra.append(x[a])                   #adicionando cada letra na lista\n",
    "        letras.append(letrasporpalavra)                 #adicionando lista de lista com as letras\n",
    "    for z in letras:                                    #passando item/lista por lista\n",
    "        for w in z:                                     #dentro da lista, passando letra por letra\n",
    "            if w in caract:                            #se estiver entre os caracteres\n",
    "                d=z.index(w)                           #pega o indice desse caracter\n",
    "                z[d] = ' '                             #substitui ele na lista por um espaço\n",
    "    for q in range(len(letras)):                      #q vai passar pelos índices da lista letras (palavra por palavra)\n",
    "        junto = ''.join(letras[q])                    #junto vai tranformar a lista de letras em palavras           \n",
    "        if len(junto)!=0: \n",
    "            if junto[0] !='@' and junto[0:5]!='https' and junto!= 'rt' and junto[0:3]!='kkk':  #retira alguns outros itens\n",
    "                final.append(junto)                 #adiciona na lista final\n",
    "    for a in range(len(final)-1):                    #passando pelo índice de cada palavra\n",
    "        if final[a] =='de' and final[a+1] == 'bobs':  #juntando de bobs em uma palavra só\n",
    "            final[a]='debobs'\n",
    "            final[a+1]=''\n",
    "    teste.Teste[i] = ' '.join(final)         #junta as palavras das mensagens e substitui as mensagens de teste.Teste"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Classificando:</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "teste.loc[: , 'Diferença de probabilidades']='x'           #cria coluna Diferença de probabilidades\n",
    "teste.loc[: , 'Classificação Digital']='z'                 # cria coluna Classificação Digital\n",
    "for i in range(len(teste)):                                   #passa por msg de teste\n",
    "    palavras = teste.Teste[i].split()                         #separa por palavra\n",
    "    probabilidaderelev =quantidademsgrelev           #probabilidade da frase ser relevante/irrelevante que tem valor inicial da\n",
    "    probabilidadeirrelev=quantidademsgirrelev        #probabilidade de uma palavra ser relevante/irrelevante no geral\n",
    "    for q in palavras:\n",
    "        if q in relevante:                             #se a palavra já existir, pega mutiplica a probabilidaderelev pela\n",
    "            probabilidaderelev*=relevante[q]           #probabilidade de aparecer essa palavra dado relevante\n",
    "        else:\n",
    "            probabilidaderelev*=1/(len(rel)+len(palavrasdiferentes))   #se a palavra não existir a probabilidade atribuída a ela é essa\n",
    "        if q in irrelevante:                               #Repete-se o processo\n",
    "            probabilidadeirrelev*= irrelevante[q]\n",
    "        else:\n",
    "            probabilidadeirrelev*= 1/(len(irrel)+len(palavrasdiferentes))\n",
    "    if probabilidaderelev> probabilidadeirrelev:   #verifica qual probabilidade é maior\n",
    "        teste['Classificação Digital'][i]='r'      # se relevante, classicfica como r\n",
    "    else:\n",
    "        teste['Classificação Digital'][i]='i'      #se irrelevante, classifica como i\n",
    "    probdifR=probabilidaderelev-probabilidadeirrelev   #calcula a diferença entre as probabilidades\n",
    "    \n",
    "    teste['Diferença de probabilidades'][i]=probdifR   #aribui o valor dessa diferença na coluna Diferença de probabilidades\n",
    "#Classifica de modo mais específico em função dessa diferença:\n",
    "teste.loc[teste['Diferença de probabilidades'] < - (10**(-10)), 'Especifico']='mi'    #muito irrelevante\n",
    "teste.loc[teste['Diferença de probabilidades'] > - (10**(-10)), 'Especifico']='i'     #irrelevante\n",
    "teste.loc[teste['Diferença de probabilidades'] > - (10**(-20)), 'Especifico']='n'     #neutro\n",
    "teste.loc[teste['Diferença de probabilidades'] >  (10**(-20)), 'Especifico']='r'      #relevante\n",
    "teste.loc[teste['Diferença de probabilidades'] >  (10**(-10)), 'Especifico']='mr'     #muito relevante\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Verificando a performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Considerando:\n",
    "* Positivos verdadeiros como marcado pelo Classificador como relevante e são relevantes\n",
    "* Positivos falsos como marcado pelo Classificador como relevante e não são relevantes\n",
    "* Negativos verdadeiros como marcado pelo Classificador como não relevante e não são relevantes\n",
    "* Negativos falsos como marcado pelo Classificador como não relevante e são relevantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A porcentagem de positivos verdadeiros é de:           62.0%\n",
      "A porcentagem de positivos falsos é de:                20.0%\n",
      "A porcentagem de negativos verdadeiros é de:           14.499999999999998%\n",
      "A porcentagem de negativos falsos é de:                3.5000000000000004%\n"
     ]
    }
   ],
   "source": [
    "pv=0     #positivo verdadeiro\n",
    "pf=0     #positivo falso\n",
    "nv=0     #negativo verdadeiro\n",
    "nf=0     #negativo falso\n",
    "for i in range(len(teste['Classificação Digital'])):      #passa por cada linha da coluna Classificação Digital\n",
    "    if teste['Classificação Digital'][i] == 'i':          #se a classificação difital for irrelevante:\n",
    "        \n",
    "        if teste.Manual[i] == 'i':                               #e a manual também, portanto é negativo verdadeiro\n",
    "            nv+=1                                                #então se adiciona 1 ao número de negativos verdadeiros\n",
    "            \n",
    "        else:                                                    #e a manual não, é negativo falso\n",
    "            nf+=1                                                #então se adiciona 1 ao número de negativos falsos\n",
    "            \n",
    "    if teste['Classificação Digital'][i] == 'r':          #se a classificação difital for relevante:\n",
    "        \n",
    "        if teste.Manual[i] == 'r':                               #e a manual também, portanto é positivo verdadeiro\n",
    "            pv+=1                                                #então se adiciona 1 ao número de positivos verdadeiros\n",
    "             \n",
    "        else:                                                    #e a manual não, é positivo falso\n",
    "            pf+=1                                                #então se adiciona 1 ao número de positios falsos\n",
    "            \n",
    "#Transformando em porcentagens:\n",
    "pf=(pf/len(teste['Classificação Digital']))*100\n",
    "pv=(pv/len(teste['Classificação Digital']))*100\n",
    "nv=(nv/len(teste['Classificação Digital']))*100\n",
    "nf=(nf/len(teste['Classificação Digital']))*100\n",
    "\n",
    "print('A porcentagem de positivos verdadeiros é de:           {}%'.format(pv))\n",
    "print('A porcentagem de positivos falsos é de:                {}%'.format(pf))\n",
    "print('A porcentagem de negativos verdadeiros é de:           {}%'.format(nv))\n",
    "print('A porcentagem de negativos falsos é de:                {}%'.format(nf))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Classificação mais específica</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Considerando:\n",
    "* Muito relevantes como mr\n",
    "* Relevantes como r\n",
    "* Neutros como n\n",
    "* Irrelevantes como i\n",
    "* Muito irrelevantes como mi\n",
    "\n",
    "Além da utilização do classificador, classificou-se as mensagens manualmente utilizando os seguintes critérios:\n",
    "* Muito relevantes como aquelas em que se há uma crítica negativa\n",
    "* Relevantes como aquelas em que há críticas positivas\n",
    "* Neutros como como aquelas que continham informações como a confirmação da presença no fast-food\n",
    "* Irrelevantes como aquelas que se referiam ao 'Bobs' de maneira geral, junto com vários fast-foods, porém sem fazer uma crítica\n",
    "* Muito irrelevantes como aquelas que não se referiam realmente ao 'Bobs'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m  Classificação Manual X Digital\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Manual</th>\n",
       "      <th>i</th>\n",
       "      <th>mi</th>\n",
       "      <th>mr</th>\n",
       "      <th>n</th>\n",
       "      <th>r</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Digital</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>i</th>\n",
       "      <td>0.5</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mi</th>\n",
       "      <td>0.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>5.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mr</th>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>46.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n</th>\n",
       "      <td>1.0</td>\n",
       "      <td>9.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r</th>\n",
       "      <td>2.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.5</td>\n",
       "      <td>6.5</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>5.5</td>\n",
       "      <td>30.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>29.5</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Manual     i    mi   mr     n     r    All\n",
       "Digital                                   \n",
       "i        0.5   6.0  0.5   0.5   1.0    8.5\n",
       "mi       0.5   4.0  0.5   0.0   0.5    5.5\n",
       "mr       1.0   6.0  3.0  17.0  19.0   46.0\n",
       "n        1.0   9.5  0.0   5.0   2.5   18.0\n",
       "r        2.5   4.5  2.0   6.5   6.5   22.0\n",
       "All      5.5  30.0  6.0  29.0  29.5  100.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "manxdig=pd.crosstab(teste.Especifico,teste.EspManual,margins=True,rownames=['Digital'] , colnames=['Manual'], normalize=True)*100\n",
    "print('\\033[1m'+'  Classificação Manual X Digital')\n",
    "manxdig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<em><b>Tabela 1:</b> Tabela comparando a classificção específica manual e a feita pelo Classificador</em>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A probabilidade de acerto do classificador, nesse caso é de 19.0%, sendo considerada muito baixa.\n"
     ]
    }
   ],
   "source": [
    "porcacerto = manxdig.i.i+manxdig.mi.mi+manxdig.r.r+manxdig.mr.mr +manxdig.n.n\n",
    "print(\"A probabilidade de acerto do classificador, nesse caso é de {}%, sendo considerada muito baixa.\".format(porcacerto))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style = \"text-indent:4em\"> A partir da análise da <em><b>Tabela 1</b></em>, percebe-se que a probabilidade de erro do Classificador torna-se muito grande. Isso ocorre, pois, no nosso contexto atual, a separação entre muito relevante, relevante, neutro, irrelevante e muito irrelevante não fica muito consistente, pois torna-se muito subjetiva para que, apenas com a frequência das palavras se possa tirar conclusões.</p>\n",
    "<p style = \"text-indent:4em\">Outro fator importante que causa a inconsistência é que o padrão de classificação precisaria ser mudado. Isso ocorre devido ao fato de que, em um primeiro momento, considerou-se na classificação apenas o relacionado a marca ou não e, para uma classificação mais específica, seria necessário considerar o nível de relevância, o qual poderia ser entendido como a classificação do que se fala da marca, o que somente seria lógico se fosse feito apenas com as consideradas anteriormente como relevantes.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "___\n",
    "## Concluindo\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<style = 'text-ident:4em'> No geral o classificador possui pontos positivos e negativos. Vale notar que no trabalho apenas classificamos como relevante twwets intimamente relacionados ao produto escolhido frente a quantidade significativa de tweets que utilizavam o nome procurado, mas que discorriam sobre outros assuntos irrelevantes para a pesquisa.\n",
    " Frente ao exposto, dentre os aspectos positivos, tem-se que o classificador esta treinado para entender a frase \"de bobs\", considerada uma gíria, como uma única palavra. Neste contexto, diminui-se a possibilidade de equívocos na classificação, posto que, é retirada a interferência da gíria na frequência da palavra do produto procurado (\"bobs\"). Outro aspecto positivo está na capacidade de considerar e classificar atributos ausentes na base de treinamento.\n",
    "    Entretanto, dentre os aspectos negativos, deve-se notar que por levar apenas a frequência das palavras de maneira independente em consideração, ou seja ignorando o significado da relação entre elas em uma frase, o classificador pode vir a cometer equívocos. Neste ínterim, sobretudo no caso de no futuro classificarmos os dados relevantes em comentários que elogiam ou denigrem o produto, levar em consideração a correlação entre as palavras torna-se amplamente necessário. Outro ponto importante é que o classificador necessita de supervisão, ou seja, de uma base de treinamento para servir de comparação na análise de amostragens desconhecidas e assim fazer previsões. Desse modo, é mister notar que não se pode usar automaticamente o próprio classificador na base de treinamento aplicado a novos tweets. Além disso, uma vez que o classificador depende de uma base já classificada, a quantidade reduzida de tweet manualmente rotulados também interfere no desempenho. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style = \"text-indent:4em\">Dentre outras utilidades do Classificador Naive-Bayes, tem-se a detecção de fraudes, filtragem de spam em e-mails, análise de risco para créditos bancários e diagnósticos médicos. No que diz respeito às fraudes e aos spams, em ambos o classificador naive-bayers se torna pertinente pois possui a capacidade de aprender frente as atualizações constantes desse contexto. Na questão do crédito bancário, é possível classificar o cliente, por exemplo, como inadimplente mediante seus dados cadastrais. Por fim, para os diagnósticos médicos, analisa-se a probabilidade do paciente possuir uma doença específica dado um ou mais sintomas determinados.</p>\n",
    "<p style = \"text-indent:4em\">No geral, o classificador realizado neste projeto possui pontos positivos e negativos. Vale notar que no trabalho apenas classificou-se como relevante tweets intimamente relacionados ao produto escolhido, a marca <em>\"Bobs\"</em>, frente a quantidade significativa de tweets que utilizavam o nome procurado, mas que discorriam sobre outros assuntos irrelevantes para a pesquisa.</p>\n",
    "<p style = \"text-indent:4em\">Diante do exposto, dentre os aspectos positivos, tem-se que o classificador está treinado para entender a expressão \"de bobs\", considerada uma gíria, como uma única palavra. Neste contexto, diminui-se a possibilidade de equívocos na classificação, posto que é retirada a interferência da gíria na frequência da palavra do produto procurado (\"bobs\"). Outro aspecto positivo está na capacidade de considerar e classificar atributos ausentes na base de treinamento.</p>\n",
    "<p style = \"text-indent:4em\">Além disso, o resultado do classificador, por mais que houve um erro de aproximadamente 24%, pode ser considerado como algo positivo, já que a porcentagem de negativos falsos(3.5%) é bem menor do que a de positivos falsos(20%). Ou seja, no contexto de uma empresa, seria melhor para ela receber positivos falsos do que negativos falsos, pois, por mais que será necessário mais mão-de-obra pois haverão mais tweets considerados relevantes e não o são, a probabilidade de que não se note um tweet importante é menor.</p>\n",
    "<p style = \"text-indent:4em\">Entretanto, dentre os aspectos negativos, deve-se notar que, por levar em consideração apenas a frequência das palavras de maneira independente, ou seja, ignorando o significado da relação entre elas em uma frase, o classificador pode vir a cometer equívocos. Entretanto, para a classificação feita, o sentido real das mensagens não foi tão crucial não sendo necessário identificar dupla negação ou sarcasmo quanto caso se quisesse classificar os dados relevantes em comentários que elogiam ou denigrem o produto,o que, para essa expansão, levar em consideração a correlação entre as palavras torna-se amplamente necessário, já que o que será analisado será o sentido.</p>\n",
    "<p style = \"text-indent:4em\">Entretanto, o computador não consegue interpretar subjetivamente as mensagens mesma maneira que pessoas, o que dificulta o processo de análise das ocorrências de sarcasmo e dupla negação. Mas, a porcentagem de tweets com esses fatores provavelmente será pequena, não alterando muito os resultados do Classificador. Porém, em épocas como quando o \"#sóquenão\" e suas variações estavam na moda, em que, normalmente se escrevia uma coisa contrária ao que realmente se queria, o processo de análise torna-se muito mais complexo.  </p>\n",
    "<p style = \"text-indent:4em\">Outro ponto importante é que o classificador necessita de supervisão, ou seja, de uma base de treinamento para servir de comparação na análise de amostragens desconhecidas e assim fazer previsões. Desse modo, é mister notar que não se pode alimentar automaticamente a base de Treinamento com a classificação realizada pelo Classificador em novos tweets, principalmente pois não será possível saber se a classificação feita nessas novas mensagens estarão corretas, o que poderia acarretar em uma alimentação equívoca do Classificador, o que afetaria o seu desempenho. Por isso, uma vez que o classificador depende de uma base já classificada, a quantidade reduzida de tweets manualmente rotulados também interfere no desempenho.</p>\n",
    "\n",
    "<p style = \"text-indent:4em\"> Em busca de possíveis melhorias para o Classificador, encontrou-se quatro maneiras:</p>\n",
    "<ol><em>\n",
    "    <li>N-grams</li>\n",
    "    <li>Tf-Idf</li>\n",
    "    <li>Stem Extraction</li>\n",
    "    <li>Levenshtein Distance</li>\n",
    "</em></ol>\n",
    "\n",
    "<h4>I) N-grams:</h4>\n",
    "<p style = \"text-indent:4em\">Levar em consideração conjuntos de palavras e suas correlações na frase. Dessa maneira, caso se encaminhe a proposta de classificar em elogios ou desmerecimentos, estabelecer diferença de significado entre certas frases tais como “muito bom” e “muito ruim” torna-se substancial. Objetivando aplicar este método deve -se aplicar condições no código nos quais a palavra dependerá das posições das “n” palavras anteriores.</p>\n",
    "\n",
    "<h4>II) Tf-Idf (Frequência do termo inverso da frequência nos documentos):</h4>\n",
    "<p style = \"text-indent:4em\">A importância de uma palavra aumenta de acordo com o número de ocorrências durante a classificação, porém esse número é equilibrado considerando a frequência desta mesma palavra nos dois grupos de relevância. Caso sua frequência seja alta em ambos significa que sua importância na classificação deveria ser reduzida, esse é o caso de palavras costumeiramente presentes no decorrer de uma frase tais como artigos. No código deve-se calcular a frequência em cada classificação (Tf) e calcular a presença em ambos (Idf) multiplicando os dois resultados obtendo-se a frequência equilibrada da palavra(Tf-Idf).</p>\n",
    "\n",
    "<h4>III) Stem Extraction:</h4>\n",
    "<p style = \"text-indent:4em\">Extrair o radical das palavras para analisar o seu sentido principal. Reunindo as diferentes maneiras de se escrever as palavras como com diminutivo e plural, classificando \"balas\" e \"bala\" da mesma maneira, já que, essencialmente, são iguais. Na <em><b>Figura 1</b></em> está presente esse processo de extração do radical de uma palavra.</p>\n",
    "<img src = 'StemExtraction.png' width=800px/>\n",
    "<em><b>Figura 1:</b> Extração do radical de uma palavra. Fonte:http://wsl.softwarelivre.org/2005/0020/20.pdf</em>\n",
    "\n",
    "<h4>IV) Levenshtein Distance</h4>\n",
    "<p style = \"text-indent:4em\">Se refere ao número mínimo de operações necessárias para transformar um string em outro. Sendo consideradas como operações a substituição, adição ou subtração de letras. Sua utilização é muito importante em corretores ortográficos,reconhecimento de fala,análise de DNA e detecção de plágio, por exemplo. Ainda assim, há casos em que pode falhar, como analisando \"mata\" e \"mala\", que tem uma distância 1, porém não tem relamente semelhança semântica.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Matriais de Pesquisa e fontes:</h4>\n",
    "<ol>\n",
    "    <li> N-grams\n",
    "        <ul>\n",
    "            <li>https://lagunita.stanford.edu/c4x/Engineering/CS-224N/asset/slp4.pdf  </li>\n",
    "           \n",
    "        </ul>\n",
    "    </li>\n",
    "    \n",
    "    <li>Tf-Idf\n",
    "        <ul>\n",
    "            <li>http://www.tfidf.com/ </li>\n",
    "        </ul>\n",
    "    </li>\n",
    "    <li> Stem Extraction\n",
    "        <ul>\n",
    "            <li>http://wsl.softwarelivre.org/2005/0020/20.pdf</li>\n",
    "        </ul>\n",
    "    </li>\n",
    "    \n",
    "    <li> Levenshtein Distance\n",
    "    <ul>\n",
    "        <li>https://people.cs.pitt.edu/~kirk/cs1501/Pruhs/Spring2006/assignments/editdistance/Levenshtein%20Distance.htm</li>\n",
    "        <li>https://pt.wikipedia.org/wiki/Dist%C3%A2ncia_Levenshtein</li>\n",
    "    </ul>\n",
    "    </li>\n",
    "    <li> Outros\n",
    "        <ul>\n",
    "            <li>https://link.springer.com/article/10.1023%2FA%3A1009976227802?LI=true</li>\n",
    "            <li>http://www.facom.ufu.br/~backes/pgc204/Aula05-ClassificadoresBaeysianos.pdf</li>\n",
    "            <li>http://www.teses.usp.br/teses/disponiveis/3/3142/tde-25052009-162507/publico/Dissertacao_Cristiane_Karcher_revisada.pdf</li>\n",
    "            <li>http://www.lbd.dcc.ufmg.br/colecoes/erbd/2013/0019.pdf</li>\n",
    "            <li>http://www.lbd.dcc.ufmg.br/colecoes/eniac/2016/059.pdf</li>\n",
    "        </ul>\n",
    "    </li>\n",
    "</ol>    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
